{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mejiap/TopicosAvanzadosEnAnalitica/blob/main/Soluciones/E1-Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "<div>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Javeriana.svg/1200px-Javeriana.svg.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "# Facultad de Ingeniería Industrial\n",
        "## Maestria en Analítica en Inteligencia de Negocio\n",
        "### Materia: Tópicos Avanzados en Analítica\n",
        "### Modúlo: Procesamiento de Lenguaje Natural"
      ],
      "metadata": {
        "id": "R36i0tfEz4Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenización\n",
        "\n",
        "En NLP el proceso de convertir nuestras secuencias de caracteres, palabras o párrafos en inputs para la computadora se llama **tokenización**. Se puede pensar al token como la unidad para procesamiento semántico."
      ],
      "metadata": {
        "id": "Nfb0e7Js1dEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv7vRwTzzXvH",
        "outputId": "ab40d953-2af7-4be2-91ea-b64805503daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¿Cuánto', 'tiempo', 'pasó', 'desde', 'que', 'comí', 'una', 'manzana?']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "tk = WhitespaceTokenizer()\n",
        "texto = \"¿Cuánto tiempo pasó desde que comí una manzana?\"\n",
        "texto_tokenizado = tk.tokenize(texto)\n",
        "print(texto_tokenizado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "como vemos *manzana* y *cuánto* figuran con el signo de pregunta. Y si tuvieramos la palabra manzana mencionada otra vez saldría nuevamente como un token diferente. Lo mismo nos sucedería si aparece una coma o un punto ¿Cómo hacemos para evitarlo?"
      ],
      "metadata": {
        "id": "FbM9INzk3HWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos utilizar `TreebankWordTokenizer` en lugar de `WhitespaceTokenizer`. También podemos preprocesar el texto quitando comas y signos de puntuación y separar por espacios, o bien utilizar opciones como `WordPunctTokenizer` que separa por palabras tomando como separadores todo lo que no sea un caracter alfabetico."
      ],
      "metadata": {
        "id": "pR4uGVu73kgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "texto = \"¿Cuánto tiempo pasó desde que comí una manzana?\"\n",
        "texto_tokenizado1 = WordPunctTokenizer().tokenize(texto)\n",
        "texto_tokenizado2 = TreebankWordTokenizer().tokenize(texto)"
      ],
      "metadata": {
        "id": "woH8Vq5W1bwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texto_tokenizado1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6D2WNuV18eX",
        "outputId": "0378d758-0c24-45b8-afa6-8e11dab50434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¿', 'Cuánto', 'tiempo', 'pasó', 'desde', 'que', 'comí', 'una', 'manzana', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texto_tokenizado2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAMX05Gx1_qW",
        "outputId": "cfb4c72b-6a90-4c85-b3a5-cdc9f4a5720c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¿Cuánto', 'tiempo', 'pasó', 'desde', 'que', 'comí', 'una', 'manzana', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como evidenciamos la opción de `TreebankWordTokenizer` es la más popular en inglés el signo de apertura de pregunta \"¿\" fue un problema para ella. Mientras que la opción de WordPunctTokenizer no tuvo ningún problema."
      ],
      "metadata": {
        "id": "Pi0PPMN038Qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿cómo crees que se comportarían frente a una apóstrofe?"
      ],
      "metadata": {
        "id": "NpqVpFFY4gxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "texto = \"¿Cuánto tiempo's pasó desde que comí una manzana?\"\n",
        "texto_tokenizado1 = WordPunctTokenizer().tokenize(texto)\n",
        "texto_tokenizado2 = TreebankWordTokenizer().tokenize(texto)"
      ],
      "metadata": {
        "id": "i3LHqWjY2ATa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texto_tokenizado1)"
      ],
      "metadata": {
        "id": "Obq_M27MgLZ7",
        "outputId": "238cc321-4eda-4468-a1f9-b2ece6e19edb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¿', 'Cuánto', 'tiempo', \"'\", 's', 'pasó', 'desde', 'que', 'comí', 'una', 'manzana', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texto_tokenizado2)"
      ],
      "metadata": {
        "id": "495A3rQOgNR-",
        "outputId": "343f6b6c-7b8a-405c-f8de-a7761da0afe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¿Cuánto', 'tiempo', \"'s\", 'pasó', 'desde', 'que', 'comí', 'una', 'manzana', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con un apostrofe la función WordPunctTokenizer logra identificarlo  y separarlo en un token diferente de la palara tiempo y de la letra o palabra que le sigue. Mientras que TreebankWordTokenizer lo identifica como un separador entre la palara tiempo y la s"
      ],
      "metadata": {
        "id": "o_DUH9dEgQuG"
      }
    }
  ]
}